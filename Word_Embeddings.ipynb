{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Word_Embeddings.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Intro_to_DL_tutorial/blob/master/Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJrH9l8GhByQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpG4AaPeiVRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Running on local machine?\n",
        "# in case of errors with conda, try this:\n",
        "# conda install -c conda-forge spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5I-oFwMiLOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for the default model in Spacy\n",
        "# nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ3YXN28h7ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f9c8bf26-c188-4f42-c200-c4a58e92b642"
      },
      "source": [
        "# for the large language model for English\n",
        "\n",
        "# uncomment the next line if default English model data cannot be located\n",
        "# !python -m spacy download en\n",
        "\n",
        "# uncomment the next line if the large model for English cannot be located\n",
        "# !python -m spacy download en_core_web_lg\n",
        "\n",
        "!python -m spacy link en_core_web_lg en --force\n",
        "# use the large model as the default model for English textual data\n",
        "\n",
        "nlp = spacy.load(\"en\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaYkgReRn31q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(vec_A, vec_B):\n",
        "    return np.dot(np.asarray(vec_A), np.asarray(vec_B)) / (np.linalg.norm(np.asarray(vec_A)) * np.linalg.norm(np.asarray(vec_B)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7tT9BzqpJHU",
        "colab_type": "text"
      },
      "source": [
        "### Will try out various Similarity Metrics for Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdqBM-vchBym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38038471-1f23-4f1d-931c-0d489c13e200"
      },
      "source": [
        "# Gender\n",
        "\n",
        "tokens = nlp(\"king man woman queen\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'king'):\n",
        "        vec_king = token.vector\n",
        "    if(token.text == 'man'):\n",
        "        vec_man = token.vector\n",
        "    if(token.text == 'woman'):\n",
        "        vec_woman = token.vector\n",
        "    if(token.text == 'queen'):\n",
        "        vec_queen = token.vector\n",
        "\n",
        "new_vec = vec_king - vec_man + vec_woman\n",
        "print(cosine_similarity(new_vec, vec_queen))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.78808445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOPh6nSfhBzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf8702e9-f372-4dbb-81a3-90d47d0b8544"
      },
      "source": [
        "# Capital Cities\n",
        "\n",
        "tokens = nlp(\"paris france tokyo japan\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'paris'):\n",
        "        vec_paris = token.vector\n",
        "    if(token.text == 'france'):\n",
        "        vec_france = token.vector\n",
        "    if(token.text == 'tokyo'):\n",
        "        vec_tokyo = token.vector\n",
        "    if(token.text == 'japan'):\n",
        "        vec_japan = token.vector\n",
        "        \n",
        "new_vec = vec_paris - vec_france + vec_japan\n",
        "print(cosine_similarity(new_vec, vec_tokyo))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.79177994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns_lz8hShBzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f334e981-c7a3-41ab-c96a-9f44e369b64a"
      },
      "source": [
        "#Pluralization\n",
        "\n",
        "tokens = nlp(\"mouse mice chair chairs\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'mouse'):\n",
        "        vec_mouse = token.vector\n",
        "    if(token.text == 'mice'):\n",
        "        vec_mice = token.vector\n",
        "    if(token.text == 'chair'):\n",
        "        vec_chair = token.vector\n",
        "    if(token.text == 'chairs'):\n",
        "        vec_chairs = token.vector\n",
        "        \n",
        "new_vec = vec_mice - vec_mouse + vec_chair\n",
        "print(cosine_similarity(new_vec, vec_chairs))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6925059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvhdv_2FhBz8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b48d5b2c-377a-44f5-ce89-a6876862344e"
      },
      "source": [
        "# Superlative Degree\n",
        "\n",
        "tokens = nlp(\"good best cold colder\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'cold'):\n",
        "        vec_cold = token.vector\n",
        "    if(token.text == 'colder'):\n",
        "        vec_colder = token.vector\n",
        "    if(token.text == 'best'):\n",
        "        vec_best = token.vector\n",
        "    if(token.text == 'good'):\n",
        "        vec_good = token.vector\n",
        "        \n",
        "new_vec = vec_colder - vec_cold + vec_good\n",
        "print(cosine_similarity(new_vec, vec_best))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4129227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SihapaMohB0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1646f44d-5f79-4881-c98a-c5bdc87e743a"
      },
      "source": [
        "# Present Participle Forms\n",
        "\n",
        "tokens = nlp(\"think thinking read reading\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'think'):\n",
        "        vec_think = token.vector\n",
        "    if(token.text == 'thinking'):\n",
        "        vec_thinking = token.vector\n",
        "    if(token.text == 'read'):\n",
        "        vec_read = token.vector\n",
        "    if(token.text == 'reading'):\n",
        "        vec_reading = token.vector\n",
        "        \n",
        "new_vec = vec_thinking - vec_think + vec_read\n",
        "print(cosine_similarity(new_vec, vec_reading))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.78735167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oMf6JRShB0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8cfd77b8-c786-42b8-bd87-6efd7db8f0c4"
      },
      "source": [
        "# Opposites\n",
        "\n",
        "tokens = nlp(\"possible impossible ethical unethical\")\n",
        "\n",
        "for token in tokens:\n",
        "    if(token.text == 'possible'):\n",
        "        vec_possible = token.vector\n",
        "    if(token.text == 'impossible'):\n",
        "        vec_impossible = token.vector\n",
        "    if(token.text == 'ethical'):\n",
        "        vec_ethical = token.vector\n",
        "    if(token.text == 'unethical'):\n",
        "        vec_unethical = token.vector\n",
        "        \n",
        "new_vec = vec_impossible - vec_possible + vec_ethical\n",
        "print(cosine_similarity(new_vec, vec_unethical))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.54883933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c9bN6nihB0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}